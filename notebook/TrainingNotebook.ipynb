{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbyGVO0YIg6W"
   },
   "source": [
    "https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb#scrollTo=GWiVUF0jIrIv\n",
    "\n",
    "https://huggingface.co/transformers/custom_datasets.html#token-classification-with-w-nut-emerging-entities\n",
    "\n",
    "https://huggingface.co/blog/ray-tune\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2j1gjgj7r4D"
   },
   "source": [
    "# Installing and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TT6pxvUmoLiN",
    "outputId": "0531edbb-db56-486c-ff04-1f714bd01ae8"
   },
   "outputs": [],
   "source": [
    "# !sudo apt install git-lfs\n",
    "!git config --global user.email aditeya.baral@gmail.com\n",
    "!git config --global user.name Aditeya\n",
    "HF_HUB_API_TOKEN = \"api_vOKpxbhcEnOqvVNYfPxOSzFoMsFNxOqttx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNyQKKbz8KWj",
    "outputId": "1379ed74-e71e-4b6f-c561-7c9c5dc919e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: seqeval in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: ray in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (2021.9.30)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (0.0.17)\n",
      "Requirement already satisfied: requests in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: dill in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from datasets) (2021.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from seqeval) (1.0)\n",
      "Requirement already satisfied: redis>=3.5.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from ray) (3.5.3)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from ray) (1.36.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from ray) (8.0.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from ray) (1.0.2)\n",
      "Requirement already satisfied: attrs in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from ray) (21.2.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from ray) (3.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from click>=7.0->ray) (0.4.4)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from grpcio>=1.28.1->ray) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->datasets) (4.0.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\adite\\miniconda3\\envs\\tf\\lib\\site-packages (from pandas->datasets) (2021.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets seqeval ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNGsoLx3zYOM",
    "outputId": "03d1fb75-33e8-486d-f701-80d6c68b3c6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mwHOf0lcudI8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, load_metric, DatasetDict\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09TpS-xDwboX"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "n0QOAl4jwOOm",
    "outputId": "aeaf5832-53bd-4003-a84b-026b6aabe0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54629, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>haiku</th>\n",
       "      <th>indices</th>\n",
       "      <th>ppl-gpt2</th>\n",
       "      <th>grammar-check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did the CIA tell the FBI that it knows the wor...</td>\n",
       "      <td>cia fbi the biggest weapon</td>\n",
       "      <td>[2, 5, 9, 24, 25]</td>\n",
       "      <td>2447.346480</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did the CIA tell the FBI that it knows the wor...</td>\n",
       "      <td>cia fbi the biggest weapon</td>\n",
       "      <td>[2, 5, 9, 24, 25]</td>\n",
       "      <td>2447.346480</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dark clouds gathered overhead,\\nExpelling bull...</td>\n",
       "      <td>clouds overhead bullets of the valley</td>\n",
       "      <td>[1, 3, 5, 6, 10, 11]</td>\n",
       "      <td>3639.095887</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A vigilante lacking of heroic qualities that\\n...</td>\n",
       "      <td>lacking qualities that damn criminals</td>\n",
       "      <td>[2, 5, 6, 11, 12]</td>\n",
       "      <td>8305.684147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(A Diamante Poem)\\nBrain\\nHeavenly, hellish\\nF...</td>\n",
       "      <td>diamante poem the sybaritic pathetic</td>\n",
       "      <td>[1, 2, 10, 18, 19]</td>\n",
       "      <td>1982.106818</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem  \\\n",
       "0  Did the CIA tell the FBI that it knows the wor...   \n",
       "1  Did the CIA tell the FBI that it knows the wor...   \n",
       "2  Dark clouds gathered overhead,\\nExpelling bull...   \n",
       "3  A vigilante lacking of heroic qualities that\\n...   \n",
       "4  (A Diamante Poem)\\nBrain\\nHeavenly, hellish\\nF...   \n",
       "\n",
       "                                   haiku               indices     ppl-gpt2  \\\n",
       "0             cia fbi the biggest weapon     [2, 5, 9, 24, 25]  2447.346480   \n",
       "1             cia fbi the biggest weapon     [2, 5, 9, 24, 25]  2447.346480   \n",
       "2  clouds overhead bullets of the valley  [1, 3, 5, 6, 10, 11]  3639.095887   \n",
       "3  lacking qualities that damn criminals     [2, 5, 6, 11, 12]  8305.684147   \n",
       "4   diamante poem the sybaritic pathetic    [1, 2, 10, 18, 19]  1982.106818   \n",
       "\n",
       "   grammar-check  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../ppl-grammar-dataset.json')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5mCmC9UYwlC0",
    "outputId": "f4f5e6a6-327a-48b4-acd4-e12f2d59e3aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     54629.000000\n",
       "mean       6511.533484\n",
       "std       13967.007052\n",
       "min           4.944884\n",
       "25%        1245.401788\n",
       "50%        2755.530497\n",
       "75%        6398.639543\n",
       "max      560770.619276\n",
       "Name: ppl-gpt2, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ppl-gpt2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIfwU5zQxvHP",
    "outputId": "e53026dc-fbc8-4f53-9dab-fe63dbe45fea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     54629\n",
       "unique        2\n",
       "top       False\n",
       "freq      54557\n",
       "Name: grammar-check, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grammar-check\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hALdVGvrx_ye"
   },
   "source": [
    "There are some hindi sentences here - clean them in the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "Z884Fm1mwxEm",
    "outputId": "b4fc8644-c6d6-49d2-a704-1c3f2fd5d6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16576, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>haiku</th>\n",
       "      <th>indices</th>\n",
       "      <th>ppl-gpt2</th>\n",
       "      <th>grammar-check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You sit left to me,\\nYou don't wanna see,\\nWha...</td>\n",
       "      <td>name extentions problem was about a tightrope</td>\n",
       "      <td>[38, 53, 56, 60, 75, 89, 90]</td>\n",
       "      <td>850.798879</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Life,\\nFrom ABC to XYZ;\\nLearning all the time...</td>\n",
       "      <td>abc xyz all perfect laws of all rules</td>\n",
       "      <td>[2, 4, 6, 11, 14, 15, 18, 20]</td>\n",
       "      <td>1279.585696</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life,\\nFrom ABC to XYZ;\\nLearning all the time...</td>\n",
       "      <td>perfect laws all rules like the beginning</td>\n",
       "      <td>[11, 14, 18, 20, 24, 25, 26]</td>\n",
       "      <td>1097.296416</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfons Schuhbeck top chef.\\nBavaria, Germany i...</td>\n",
       "      <td>chef chefs a wonderful cookbook</td>\n",
       "      <td>[3, 11, 14, 15, 16]</td>\n",
       "      <td>974.032754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Actress Angela Oberer passing a moment, Angela...</td>\n",
       "      <td>moment eyes a long time</td>\n",
       "      <td>[5, 27, 34, 35, 36]</td>\n",
       "      <td>445.035082</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem  \\\n",
       "0  You sit left to me,\\nYou don't wanna see,\\nWha...   \n",
       "1  Life,\\nFrom ABC to XYZ;\\nLearning all the time...   \n",
       "2  Life,\\nFrom ABC to XYZ;\\nLearning all the time...   \n",
       "3  Alfons Schuhbeck top chef.\\nBavaria, Germany i...   \n",
       "4  Actress Angela Oberer passing a moment, Angela...   \n",
       "\n",
       "                                           haiku  \\\n",
       "0  name extentions problem was about a tightrope   \n",
       "1          abc xyz all perfect laws of all rules   \n",
       "2      perfect laws all rules like the beginning   \n",
       "3                chef chefs a wonderful cookbook   \n",
       "4                        moment eyes a long time   \n",
       "\n",
       "                         indices     ppl-gpt2  grammar-check  \n",
       "0   [38, 53, 56, 60, 75, 89, 90]   850.798879          False  \n",
       "1  [2, 4, 6, 11, 14, 15, 18, 20]  1279.585696          False  \n",
       "2   [11, 14, 18, 20, 24, 25, 26]  1097.296416          False  \n",
       "3            [3, 11, 14, 15, 16]   974.032754          False  \n",
       "4            [5, 27, 34, 35, 36]   445.035082          False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df[\"ppl-gpt2\"] <= 1500]\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "print(filtered_df.shape)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5QODxUIy8qh"
   },
   "source": [
    "# Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1SdvncGxe4U",
    "outputId": "824e420c-02b1-4971-879a-9ef57dfd18cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adite\\AppData\\Local\\Temp/ipykernel_7484/3062880647.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"tokens\"] = filtered_df[\"poem\"].apply(lambda x: word_tokenize(x))\n",
      "C:\\Users\\adite\\AppData\\Local\\Temp/ipykernel_7484/3062880647.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"ner_tags\"] = ner_tags\n"
     ]
    }
   ],
   "source": [
    "filtered_df[\"tokens\"] = filtered_df[\"poem\"].apply(lambda x: word_tokenize(x))\n",
    "ner_tags = list()\n",
    "for i in range(filtered_df.shape[0]):\n",
    "  indices = filtered_df[\"indices\"][i]\n",
    "  length = len(filtered_df[\"tokens\"][i])\n",
    "  ner_tag = ['O' for _ in range(length)]\n",
    "  for idx in indices:\n",
    "    ner_tag[idx] = 'W'\n",
    "  ner_tags.append(ner_tag)\n",
    "filtered_df[\"ner_tags\"] = ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhWWw1LHzHNd",
    "outputId": "9474de8c-c467-48d3-cefe-fda726b87762"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>haiku</th>\n",
       "      <th>indices</th>\n",
       "      <th>ppl-gpt2</th>\n",
       "      <th>grammar-check</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You sit left to me,\\nYou don't wanna see,\\nWha...</td>\n",
       "      <td>name extentions problem was about a tightrope</td>\n",
       "      <td>[38, 53, 56, 60, 75, 89, 90]</td>\n",
       "      <td>850.798879</td>\n",
       "      <td>False</td>\n",
       "      <td>[You, sit, left, to, me, ,, You, do, n't, wan,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Life,\\nFrom ABC to XYZ;\\nLearning all the time...</td>\n",
       "      <td>abc xyz all perfect laws of all rules</td>\n",
       "      <td>[2, 4, 6, 11, 14, 15, 18, 20]</td>\n",
       "      <td>1279.585696</td>\n",
       "      <td>False</td>\n",
       "      <td>[Life, ,, From, ABC, to, XYZ, ;, Learning, all...</td>\n",
       "      <td>[O, O, W, O, W, O, W, O, O, O, O, W, O, O, W, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life,\\nFrom ABC to XYZ;\\nLearning all the time...</td>\n",
       "      <td>perfect laws all rules like the beginning</td>\n",
       "      <td>[11, 14, 18, 20, 24, 25, 26]</td>\n",
       "      <td>1097.296416</td>\n",
       "      <td>False</td>\n",
       "      <td>[Life, ,, From, ABC, to, XYZ, ;, Learning, all...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, W, O, O, W, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfons Schuhbeck top chef.\\nBavaria, Germany i...</td>\n",
       "      <td>chef chefs a wonderful cookbook</td>\n",
       "      <td>[3, 11, 14, 15, 16]</td>\n",
       "      <td>974.032754</td>\n",
       "      <td>False</td>\n",
       "      <td>[Alfons, Schuhbeck, top, chef, ., Bavaria, ,, ...</td>\n",
       "      <td>[O, O, O, W, O, O, O, O, O, O, O, W, O, O, W, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Actress Angela Oberer passing a moment, Angela...</td>\n",
       "      <td>moment eyes a long time</td>\n",
       "      <td>[5, 27, 34, 35, 36]</td>\n",
       "      <td>445.035082</td>\n",
       "      <td>False</td>\n",
       "      <td>[Actress, Angela, Oberer, passing, a, moment, ...</td>\n",
       "      <td>[O, O, O, O, O, W, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem  \\\n",
       "0  You sit left to me,\\nYou don't wanna see,\\nWha...   \n",
       "1  Life,\\nFrom ABC to XYZ;\\nLearning all the time...   \n",
       "2  Life,\\nFrom ABC to XYZ;\\nLearning all the time...   \n",
       "3  Alfons Schuhbeck top chef.\\nBavaria, Germany i...   \n",
       "4  Actress Angela Oberer passing a moment, Angela...   \n",
       "\n",
       "                                           haiku  \\\n",
       "0  name extentions problem was about a tightrope   \n",
       "1          abc xyz all perfect laws of all rules   \n",
       "2      perfect laws all rules like the beginning   \n",
       "3                chef chefs a wonderful cookbook   \n",
       "4                        moment eyes a long time   \n",
       "\n",
       "                         indices     ppl-gpt2  grammar-check  \\\n",
       "0   [38, 53, 56, 60, 75, 89, 90]   850.798879          False   \n",
       "1  [2, 4, 6, 11, 14, 15, 18, 20]  1279.585696          False   \n",
       "2   [11, 14, 18, 20, 24, 25, 26]  1097.296416          False   \n",
       "3            [3, 11, 14, 15, 16]   974.032754          False   \n",
       "4            [5, 27, 34, 35, 36]   445.035082          False   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [You, sit, left, to, me, ,, You, do, n't, wan,...   \n",
       "1  [Life, ,, From, ABC, to, XYZ, ;, Learning, all...   \n",
       "2  [Life, ,, From, ABC, to, XYZ, ;, Learning, all...   \n",
       "3  [Alfons, Schuhbeck, top, chef, ., Bavaria, ,, ...   \n",
       "4  [Actress, Angela, Oberer, passing, a, moment, ...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, W, O, W, O, W, O, O, O, O, W, O, O, W, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, W, O, O, W, ...  \n",
       "3  [O, O, O, W, O, O, O, O, O, O, O, W, O, O, W, ...  \n",
       "4  [O, O, O, O, O, W, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8D7ZU0dS1wL0",
    "outputId": "95e88b0d-ab04-4220-ceb3-25e21011ac62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15747, 7) (829, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(filtered_df, test_size=0.05)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WK4k1k4YFsvy"
   },
   "outputs": [],
   "source": [
    "tokens = filtered_df[\"tokens\"]\n",
    "tags = filtered_df[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0sNQcvxsF0uz"
   },
   "outputs": [],
   "source": [
    "unique_tags = [\"O\", \"W\"]\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YxEy-Bd4-1ip"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9U4aLJ9c-xu"
   },
   "source": [
    "# Initialising GPT-2 for Perplexity Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "d3051LjVPrGk"
   },
   "outputs": [],
   "source": [
    "gpt2_model_name = \"gpt2\"\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_model_name)\n",
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(gpt2_model_name)\n",
    "\n",
    "def perplexityGPT2(sentences):\n",
    "  ppl = list()\n",
    "  total_length = len(sentences)\n",
    "  for index, sent in enumerate(sentences):\n",
    "    tokenize_input = gpt2_tokenizer.encode(sent)\n",
    "    tensor_input = torch.tensor([tokenize_input])\n",
    "    loss = gpt2_model(tensor_input, labels=tensor_input)[0]\n",
    "    ppl.append(math.exp(loss))\n",
    "  return ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNKBMSX71sex"
   },
   "source": [
    "# Setting Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1FxXFCeHBR88"
   },
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LBssIbi2zQ7N"
   },
   "outputs": [],
   "source": [
    "if \"roberta\" in model_name:\n",
    "  tokenizer = RobertaTokenizerFast.from_pretrained(model_name, add_prefix_space=True)\n",
    "elif \"gpt2\" in model_name:\n",
    "  tokenizer = GPT2TokenizerFast.from_pretrained(model_name, add_prefix_space=True) \n",
    "  tokenizer.add_special_tokens({'pad_token': '[PAD]'}) \n",
    "else:\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9w1OAErnGDXk"
   },
   "outputs": [],
   "source": [
    "train_texts = list(train_df[\"tokens\"].values)\n",
    "val_texts = list(test_df[\"tokens\"].values)\n",
    "\n",
    "train_tags = list(train_df[\"ner_tags\"].values)\n",
    "val_tags = list(test_df[\"ner_tags\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "p8O_9mLcKJeH"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1d08s4CBG1vt"
   },
   "outputs": [],
   "source": [
    "def encode_tags(tags, encodings):\n",
    "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        try:\n",
    "          doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "          encoded_labels.append(doc_enc_labels.tolist())\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "train_labels = encode_tags(train_tags, train_encodings)\n",
    "val_labels = encode_tags(val_tags, val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lbVuzJyqKzGP"
   },
   "outputs": [],
   "source": [
    "class MapleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "offset_mapping_train = train_encodings.pop(\"offset_mapping\")\n",
    "offset_mapping_val = val_encodings.pop(\"offset_mapping\")\n",
    "train_dataset = MapleDataset(train_encodings, train_labels)\n",
    "val_dataset = MapleDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeUyLMKs9Oyu",
    "outputId": "993b01c9-e2d0-4ef0-cf66-cf53a39034f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2ForTokenClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.5.attn.masked_bias', 'classifier.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'classifier.weight', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.4.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "'''def model_init():\n",
    "  return AutoModelForTokenClassification.from_pretrained(model_name, num_labels=2, return_dict=True)'''\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bw5jPN3VDHpM"
   },
   "outputs": [],
   "source": [
    "class PerplexityTrainer(Trainer):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "  def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    batch_size = len(inputs[\"input_ids\"])\n",
    "    poems = list()\n",
    "    for i in range(batch_size):\n",
    "      text = tokenizer.decode(inputs[\"input_ids\"][i])\n",
    "      tokenized_text = tokenizer.tokenize(text)\n",
    "      labels = inputs[\"labels\"][i].tolist()\n",
    "      words = list()\n",
    "      for idx, value in enumerate(labels):\n",
    "        if value == 1:\n",
    "          words.append(tokenized_text[idx])\n",
    "      poem = ' '.join(words)\n",
    "      poems.append(poem)\n",
    "    perplexity_scores = perplexityGPT2(poems)\n",
    "    perplexity_loss = sum(perplexity_scores)\n",
    "    loss = torch.tensor(perplexity_loss, requires_grad=True)\n",
    "    return (loss, poems) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JHQQWZmpA34H"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"modelfolder\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iAlCAHr1j6Nl"
   },
   "outputs": [],
   "source": [
    "trainer = PerplexityTrainer(\n",
    "    # model_init=model_init,                        \n",
    "    model=model,\n",
    "    args=args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZVmi-grXkVzE",
    "outputId": "55b5d797-b7be-4252-bfda-9118d2146e84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainer.hyperparameter_search(\\n    direction=\"maximize\", \\n    backend=\"ray\", \\n    n_trials=10\\n)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''trainer.hyperparameter_search(\n",
    "    direction=\"maximize\", \n",
    "    backend=\"ray\", \n",
    "    n_trials=10\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ootd96ziAzP9"
   },
   "source": [
    "# Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "yJDFu9Qectm-",
    "outputId": "016b7bdb-fd32-4570-c673-01a6fd6c3c81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10730\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6710\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='670' max='6710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 670/6710 17:47 < 2:40:49, 0.63 it/s, Epoch 1.00/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7484/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1839\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7484/3711731533.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m     16\u001b[0m       \u001b[0mpoem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m       \u001b[0mpoems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mperplexity_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperplexityGPT2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mperplexity_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperplexity_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperplexity_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7484/3757401126.py\u001b[0m in \u001b[0;36mperplexityGPT2\u001b[1;34m(sentences)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtokenize_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpt2_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtensor_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenize_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpt2_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mppl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mppl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    974\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huqycSPiES-o"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTarAtZ6378d"
   },
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWohLdD3ow0J"
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(f\"maple-{model_name.lower()}\", use_auth_token=HF_HUB_API_TOKEN)\n",
    "# tokenizer.push_to_hub(f\"maple-{model_name.lower()}\", use_auth_token=HF_HUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t7gzHkZDqSv"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"/content/drive/MyDrive/Maple/maple-{model_name.lower()}\")\n",
    "trainer.save_model(f\"/content/drive/MyDrive/Maple/maple-{model_name.lower()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrXmSY-uMYIy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "X2j1gjgj7r4D",
    "09TpS-xDwboX",
    "l5QODxUIy8qh",
    "g9U4aLJ9c-xu",
    "YTarAtZ6378d"
   ],
   "machine_shape": "hm",
   "name": "Maple - Transformer Token Classification with Perplexity",
   "provenance": []
  },
  "interpreter": {
   "hash": "00bcf6c82b59e9741daa5a3d78becd13b5b298f7d43a2b1ea4edd03905860d8c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
